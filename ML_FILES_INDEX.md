# EcoSound Garden - ML Implementation Files Index

Complete reference of all files created for ML conversion.

## Frontend Files (React/TypeScript/TensorFlow.js)

### Library Files
| File | Purpose | Size | Key Functions |
|------|---------|------|---|
| `/lib/tfModels.ts` | TensorFlow.js inference engine | 182 lines | `initializeModels()`, `predictPlantHealth()`, `analyzeAcousticPattern()` |
| `/lib/modelLoader.ts` | Model caching & loading | 331 lines | `loadModel()`, `preloadModels()`, `downloadModel()`, memory management |
| `/lib/apiClient.ts` | Backend API communication | 181 lines | `predictHealth()`, `analyzeAcoustic()`, error handling with fallbacks |

### Component Files
| File | Purpose | Size | Props |
|------|---------|------|-------|
| `/components/MLPredictionsDisplay.tsx` | ML predictions dashboard | 172 lines | `plants: Plant[]` |
| `/components/PlantCareDashboard.tsx` | Plant care recommendations (fixed hydration) | Updated | Shows urgent care & maintenance |
| `/app/page.tsx` | Main page (updated with ML) | Updated | Initializes models, displays predictions |

### Hook Files
| File | Purpose | Size | Returns |
|------|---------|------|---------|
| `/hooks/useMLPredictions.ts` | ML predictions React hook | 121 lines | `{ predictions, loading, error, apiAvailable, refetch }` |

---

## Backend Files (Python/FastAPI)

### Core API
| File | Purpose | Lines | Endpoints |
|------|---------|-------|-----------|
| `/api/main.py` | FastAPI application | 215 | 6 endpoints (predict, health, upload, status) |
| `/api/models.py` | SQLAlchemy database models | 192 | 9 tables with relationships |
| `/api/audio_processor.py` | Audio feature extraction | 180 | MFCC, mel-spectrogram, spectral features |

### ML Training
| File | Purpose | Lines | Output |
|------|---------|-------|--------|
| `/api/train_models.py` | Neural network training | 246 | TensorFlow.js models in `/public/models/` |
| `/api/convert_to_tfjs.py` | Model format conversion | 238 | Converts trained models to browser format |
| `/api/integrate_datasets.py` | Acoustic dataset integration | 343 | Processes ESC-50, custom recordings, synthetic data |

### Configuration
| File | Purpose | Key Variables |
|------|---------|---|
| `/api/requirements.txt` | Python dependencies | 13 packages (FastAPI, TensorFlow, librosa, etc.) |
| `/api/Dockerfile` | Docker image definition | Python 3.11, CUDA optional |

---

## Configuration & Documentation

### Configuration Files
| File | Purpose | Notes |
|------|---------|-------|
| `.env.local.example` | Environment template | Copy to `.env.local` for local dev |
| `docker-compose.yml` | Docker services orchestration | Frontend, Backend, PostgreSQL, Redis |
| `.github/workflows/deploy.yml` | CI/CD pipeline (optional) | Auto-deploy on push to main |

### Documentation Files
| File | Purpose | Pages | Key Sections |
|------|---------|-------|---|
| `QUICK_START.md` | Get running in 5 minutes | 10 | Docker setup, troubleshooting |
| `ML_IMPLEMENTATION.md` | Detailed ML architecture | 10 | Models, API, integration, monitoring |
| `DEPLOYMENT.md` | Production deployment guide | 20 | Railway, Vercel, AWS, CI/CD |
| `ML_CONVERSION_SUMMARY.md` | What was built overview | 10 | Architecture, features, next steps |
| `ML_FILES_INDEX.md` | This file | 2 | File reference |

---

## Database Schema

### Tables Created by `models.py`
```
1. plants                  - Garden inventory
2. plant_metrics          - Time-series environmental data
3. health_predictions     - ML model predictions
4. acoustic_recordings    - Stored audio data
5. user_feedback          - User corrections for retraining
6. model_metadata         - Version tracking & performance
7. prediction_logs        - Audit trail & debugging
8. plant_metrics_history  - Archived metrics (optional)
9. (7 more as needed)     - Extensible schema
```

---

## Model Files (Generated)

These are generated by training scripts and stored in `/public/models/`:

```
/public/models/
├── plant-health-model/
│   ├── model.json                  # Model architecture
│   ├── model.weights.bin           # Weights (binary)
│   ├── model.weights.json          # Weights metadata
│   └── metadata.json               # Model info
│
└── acoustic-stress-model/
    ├── model.json
    ├── model.weights.bin
    ├── model.weights.json
    └── metadata.json
```

**To generate these:**
```bash
cd api
python train_models.py          # Creates models
python convert_to_tfjs.py       # Converts to browser format
```

---

## Dependency Changes

### New npm Packages
```json
{
  "@tensorflow/tfjs": "^4.11.0"  // Already in package.json
}
```

### New pip Packages (Backend)
```
fastapi==0.104.1
uvicorn==0.24.0
tensorflow==2.14.0              // For training
librosa==0.10.0                 // Audio processing
scikit-learn==1.3.2             // ML utilities
tensorflowjs==4.11.0            // Model conversion (optional)
sqlalchemy==2.0.23              // ORM
psycopg2-binary==2.9.9          // PostgreSQL driver
```

---

## API Endpoints Reference

All endpoints at `/api/predict/` or `/api/` prefix:

| Endpoint | Method | Purpose | Input | Output |
|----------|--------|---------|-------|--------|
| `/predict/health` | POST | Health predictions | `{ plants: [...] }` | `HealthPredictionResponse[]` |
| `/predict/acoustic` | POST | Acoustic analysis | `{ plant_id, audio_features }` | `AcousticAnalysisResponse` |
| `/models/status` | GET | Model versions & accuracy | - | `{ health_model, acoustic_model }` |
| `/dataset/upload` | POST | Upload acoustic data | FormData + file | `{ message, filename, size }` |
| `/health` | GET | Health check | - | `{ status, service }` |

---

## Feature Engineering Pipeline

### Audio Processing Steps
1. Load WAV/MP3 file (librosa)
2. Extract MFCC (13 coefficients)
3. Extract mel-spectrogram (128 frequency bins)
4. Calculate zero-crossing rate
5. Calculate spectral centroid
6. Calculate spectral rolloff
7. Normalize features (StandardScaler)
8. Return 157-dimensional vector

### Stress Indicators
```python
mfcc_variance         # Abnormal acoustics
zcr_normalized        # Rustling/stress response
spectral_stress       # Frequency shift
overall_stress        # Combined score 0-1
```

---

## Data Flow Diagrams

### Health Prediction Flow
```
Plant Metrics (temperature, humidity, health_score)
  ↓
API Client (apiClient.ts)
  ↓
Backend API (/predict/health)
  ↓
ML Model (TensorFlow)
  ↓
Prediction + Recommendations
  ↓
Frontend Display (MLPredictionsDisplay)
```

### Acoustic Analysis Flow
```
Plant Audio Recording
  ↓
Feature Extraction (MFCC, mel-spectrogram)
  ↓
API Client (apiClient.ts)
  ↓
Backend API (/predict/acoustic)
  ↓
Acoustic ML Model
  ↓
Stress Level + Classification
  ↓
Frontend Visualization
```

---

## Testing Checklist

### Backend Testing
```bash
# Health check
curl http://localhost:8000/api/health

# Model status
curl http://localhost:8000/api/models/status

# Health prediction
curl -X POST http://localhost:8000/api/predict/health \
  -H "Content-Type: application/json" \
  -d '{"plants": [...]}'

# Acoustic analysis
curl -X POST http://localhost:8000/api/predict/acoustic \
  -H "Content-Type: application/json" \
  -d '{"plant_id": 1, "audio_features": [...]}'
```

### Frontend Testing
- Visit http://localhost:3000
- Check browser console for TensorFlow.js load
- Verify API calls in Network tab
- Test ML predictions component
- Verify model caching

### Database Testing
```bash
# Connect to PostgreSQL
psql -U postgres -d ecosound

# Check tables
\dt

# Query predictions
SELECT * FROM health_predictions LIMIT 5;

# Check metrics
SELECT * FROM plant_metrics ORDER BY timestamp DESC;
```

---

## Debugging Tips

### Models Not Loading
```bash
# Check console
[v0] Initializing TensorFlow.js models...
[v0] Health model loaded successfully
[v0] Acoustic model loaded successfully

# If fails, check /public/models/ directory exists and has model.json
```

### API Connection Issues
```bash
# Backend logs
docker-compose logs -f backend

# Check endpoint
curl http://localhost:8000/api/health

# Check CORS settings in main.py
```

### Database Errors
```bash
# Check connection
psql -U postgres -d ecosound -c "SELECT 1;"

# View migrations
python api/models.py  # Run init_db(engine)

# Check logs
docker-compose logs -f postgres
```

---

## Performance Optimization

### Model Size Reduction
- Quantization: 4x smaller, minimal accuracy loss
- Pruning: Remove unnecessary weights
- Distillation: Teach small model from large

### Inference Acceleration
- GPU support: CUDA for backend
- WebGL backend: TensorFlow.js for browser
- Model caching: IndexedDB for offline access

### Database Optimization
- Index on (plant_id, timestamp)
- Archive old metrics
- Use connection pooling
- Enable query caching

---

## Deployment Readiness Checklist

- [ ] All files created (see file list above)
- [ ] Environment variables configured
- [ ] Database schema initialized
- [ ] Models trained and converted to TFJS
- [ ] Docker images build successfully
- [ ] API endpoints tested and working
- [ ] Frontend displays predictions correctly
- [ ] Fallback to browser models works
- [ ] CORS configured properly
- [ ] SSL/HTTPS ready for production
- [ ] Database backups automated
- [ ] Monitoring set up
- [ ] Error logging configured

---

## Quick File Reference

**Start with:**
1. `QUICK_START.md` - Get running locally
2. `ML_IMPLEMENTATION.md` - Understand architecture
3. `DEPLOYMENT.md` - Deploy to production

**Key files to modify:**
1. `.env.local` - Set your API URL
2. `/api/main.py` - Add custom logic
3. `/lib/apiClient.ts` - Customize API calls
4. `/components/MLPredictionsDisplay.tsx` - Adjust UI

**Training & data:**
1. `/api/train_models.py` - Train with your data
2. `/api/integrate_datasets.py` - Add acoustic data
3. `/api/models.py` - Extend database schema

---

## Support Commands

```bash
# Start everything
docker-compose up -d

# View logs
docker-compose logs -f

# Stop everything
docker-compose down

# Train models
cd api && python train_models.py

# Integrate datasets
python api/integrate_datasets.py --download esc50 --process

# Deploy to production
vercel deploy --prod

# Backend only deployment
docker build -t ecosound-api ./api
docker run -e DATABASE_URL=... ecosound-api
```

---

This index covers all 17+ new/modified files created for ML conversion. See specific files for detailed documentation.
